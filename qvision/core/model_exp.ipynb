{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Installing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install -q datasets transformers accelerate timm\n",
    "!pip install -q -U albumentations>=1.4.5 torchmetrics pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'models' from 'torchvision.models' (/Users/darky/Documents/Q-Vision/base/lib/python3.12/site-packages/torchvision/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'models' from 'torchvision.models' (/Users/darky/Documents/Q-Vision/base/lib/python3.12/site-packages/torchvision/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.models import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Playing with DATA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"here\")\n",
    "project = rf.workspace(\"roboflow-100\").project(\"uno-deck\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(img_path):\n",
    "\n",
    "  \"\"\"\n",
    "    Compare different sizes of YOLOv8 models for Uno.\n",
    "    \n",
    "    Parameters:\n",
    "\n",
    "    image_path : str\n",
    "        Path to the input image for object detection\n",
    "    \n",
    "    Returns:\n",
    "\n",
    "    dict\n",
    "        A dictionary containing detection results and performance metrics \n",
    "        for each model size\n",
    "  \"\"\"\n",
    "    model_sizes = ['n','s','m','l']\n",
    "  img = cv2.imread(img_path)\n",
    "\n",
    "  detection_results = {} # -> dictionary to store results\n",
    "\n",
    "  for size in model_sizes:\n",
    "\n",
    "    model = YOLO(f'yolov8{size}.pt')\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    results = model(img)\n",
    "    end = time.time() - start\n",
    "\n",
    "    result = results[0]\n",
    "    \n",
    "    detection_results[size] = {\n",
    "            'inference_time': end,\n",
    "            'num_detections': len(result.boxes),\n",
    "            'confidence_scores': result.boxes.conf.tolist() if len(result.boxes) > 0 else [],\n",
    "            'classes': result.boxes.cls.tolist() if len(result.boxes) > 0 else []\n",
    "        }\n",
    "    \n",
    "    annotated_frame = result.plot()\n",
    "    cv2.imwrite(f'yolov8{size}_result.jpg', annotated_frame)\n",
    "    \n",
    "  return detection_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(results):\n",
    "    \"\"\"\n",
    "    Analyze and compare the detection results across different model sizes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Dictionary of detection results from different YOLO model sizes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Prints a detailed comparison and creates visualizations\n",
    "    \"\"\"\n",
    "    model_sizes = list(results.keys())\n",
    "    inference_time = [results[size]['inference_time'] for size in model_sizes]\n",
    "    num_detections = [results[size]['num_detections'] for size in model_sizes]\n",
    "\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2, figsize = (12,5))\n",
    "\n",
    "    ax1.bar(model_sizes, inference_time)\n",
    "    ax2.set_title('Inference time comparision')\n",
    "    ax2.set_xlabel('Model')\n",
    "    ax2.set_ylabel('Inf time')\n",
    "\n",
    "    ax2.bar(model_sizes, num_detections)\n",
    "    ax2.set_title('Number of detections')\n",
    "    ax2.set_xlabel('Model')\n",
    "    ax2.set_ylabel('Num of Detections')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
